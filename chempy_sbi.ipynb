{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-04T13:13:44.044804Z",
     "start_time": "2024-08-04T13:13:38.057545Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bguenes/miniconda3/envs/master_chempy_multi/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from Chempy.parameter import ModelParameters\n",
    "\n",
    "import sbi.utils as utils\n",
    "from sbi.inference.base import infer\n",
    "\n",
    "import torch\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "import time as t\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Neural Network to simulate Chempy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "642bae8e580878ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------ Load & prepare the data ------\n",
    "\n",
    "# --- Load in training data ---\n",
    "path_training = '../ChempyMulti/tutorial_data/TNG_Training_Data.npz'\n",
    "training_data = np.load(path_training, mmap_mode='r')\n",
    "\n",
    "elements = training_data['elements']\n",
    "train_x = training_data['params']\n",
    "train_y = training_data['abundances']\n",
    "\n",
    "\n",
    "# ---  Load in the validation data ---\n",
    "path_test = '../ChempyMulti/tutorial_data/TNG_Test_Data.npz'\n",
    "val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "val_x = val_data['params']\n",
    "val_y = val_data['abundances']\n",
    "\n",
    "\n",
    "# --- Clean the data ---\n",
    "def clean_data(x, y):\n",
    "    # Remove all zeros from the training data\n",
    "    index = np.where((y == 0).all(axis=1))[0]\n",
    "    x = np.delete(x, index, axis=0)\n",
    "    y = np.delete(y, index, axis=0)\n",
    "\n",
    "    # Remove all infinite values from the training data\n",
    "    index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_x, train_y = clean_data(train_x, train_y)\n",
    "val_x, val_y     = clean_data(val_x, val_y)\n",
    "\n",
    "\n",
    "# --- Normalize the data ---\n",
    "x_mean, x_std = train_x.mean(axis=0), train_x.std(axis=0)\n",
    "y_mean, y_std = train_y.mean(axis=0), train_y.std(axis=0)\n",
    "\n",
    "\n",
    "def normalize_data(x, y, x_mean=x_mean, x_std=x_std, y_mean=y_mean, y_std=y_std):\n",
    "    x = (x - x_mean) / x_std\n",
    "    y = (y - y_mean) / y_std\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_x, train_y = normalize_data(train_x, train_y)\n",
    "val_x, val_y     = normalize_data(val_x, val_y)\n",
    "\n",
    "\n",
    "# add time squared as parameter\n",
    "def add_time_squared(x):\n",
    "    return np.concatenate((x, (x[:, -1]**2).reshape((len(x), 1))), axis=1)\n",
    "\n",
    "\n",
    "train_x = add_time_squared(train_x)\n",
    "val_x = add_time_squared(val_x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d556874e9ccdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Train the neural network -----\n",
    "\n",
    "# --- Define the neural network ---\n",
    "def single_regressor(x, y, neurons=40, epochs=3000, verbose=False):\n",
    "    \"\"\"Return out-of-sample score for a given number of neurons for one element\"\"\"\n",
    "    model = MLPRegressor(solver='adam', alpha=0.001, max_iter=epochs, learning_rate='adaptive', tol=1e-13,\n",
    "                         hidden_layer_sizes=(neurons,), activation='tanh', verbose=verbose,\n",
    "                         shuffle=True, early_stopping=True)\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    model_pred = model.predict(x)\n",
    "    score = np.mean((model_pred-y)**2.)\n",
    "    diff = np.abs(y-model_pred)\n",
    "\n",
    "    w0, w1 = model.coefs_\n",
    "    b0, b1 = model.intercepts_\n",
    "\n",
    "    return score, diff, [w0, w1, b0, b1]\n",
    "\n",
    "\n",
    "# --- Train the neural network ---\n",
    "# Train an independent neural network for each element and save the weights\n",
    "output = []\n",
    "neurons = 40\n",
    "for el_i, el in enumerate(elements):\n",
    "    print(\"Running net %d of %d\" % (el_i + 1, len(elements)))\n",
    "    o = single_regressor(train_x, train_y[:, el_i], neurons=neurons, epochs=3000, verbose=False)\n",
    "    print(\"Score for element %s is %.3f\" % (el, o[0]))\n",
    "    output.append(o)\n",
    "\n",
    "\n",
    "# --- Save the neural network outputs ---\n",
    "scores = [score for score, _, _ in output]\n",
    "diffs = [diff for _, diff, _ in output]\n",
    "coeffs = [co for _, _, co in output]\n",
    "\n",
    "w0 = np.hstack([co[0] for co in coeffs])\n",
    "b0 = np.hstack([co[2] for co in coeffs])\n",
    "b1 = np.hstack([co[3] for co in coeffs])\n",
    "\n",
    "# Read in w1 vector into sparse structure\n",
    "w1 = np.zeros([w0.shape[1], b1.shape[0]])\n",
    "assert neurons == w0.shape[1] / len(coeffs)\n",
    "for i in range(len(coeffs)):\n",
    "    w1[int(neurons * i):int(neurons * (i + 1)), i] = coeffs[i][1][:, 0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8bba6990ccab0a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Save the weights and normalization parameters ---\n",
    "# Save output\n",
    "np.savez('data/tutorial_weights.npz',\n",
    "         w0=w0, w1=w1, b0=b0, b1=b1,\n",
    "         in_mean=x_mean, in_std=x_std, out_mean=y_mean, out_std=y_std,\n",
    "         activation='tanh', neurons=neurons)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "363d8b3fe9be7467"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train SBI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ea71c69fff65021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Load the Network -----\n",
    "# Load network weights trained in train_chempyNN.py\n",
    "x = np.load('data/tutorial_weights.npz')\n",
    "\n",
    "w0 = x['w0']\n",
    "w1 = x['w1']\n",
    "b0 = x['b0']\n",
    "b1 = x['b1']\n",
    "in_mean = x['in_mean']\n",
    "in_std = x['in_std']\n",
    "out_mean = x['out_mean']\n",
    "out_std = x['out_std']\n",
    "activation = x['activation']\n",
    "neurons = x['neurons']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2bf4e920a295be3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Set-up the Simulator -----\n",
    "def add_time_squared(x):\n",
    "    return np.concatenate((x, (x[:, -1]**2).reshape((len(x), 1))), axis=1)\n",
    "\n",
    "\n",
    "def stacked_net_output(in_par):\n",
    "    in_par = (in_par - in_mean) / in_std\n",
    "    in_par = add_time_squared(in_par)\n",
    "\n",
    "    l1 = np.matmul(in_par, w0) + b0\n",
    "    l2 = np.matmul(np.tanh(l1), w1) + b1\n",
    "\n",
    "    return l2 * out_std + out_mean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d8894d56d2b47cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Set-up priors -----\n",
    "a = ModelParameters()\n",
    "priors = torch.tensor([[a.priors[opt][0], a.priors[opt][1]] for opt in a.to_optimize])\n",
    "\n",
    "combined_priors = utils.MultipleIndependent(\n",
    "    [Normal(p[0]*torch.ones(1), p[1]*torch.ones(1)) for p in priors] +\n",
    "    [Uniform(torch.tensor([2.0]), torch.tensor([12.8]))],\n",
    "    validate_args=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "666980b6d732cffa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- sbi setup -----\n",
    "num_sim = 100000\n",
    "method = 'SNPE' #SNPE or SNLE or SNRE\n",
    "\n",
    "start = t.time()\n",
    "posterior = infer(\n",
    "    stacked_net_output,\n",
    "    combined_priors,\n",
    "    method=method,\n",
    "    num_simulations=num_sim)\n",
    "\n",
    "print(f'Time taken to train the posterior with {num_sim} samples: {round(t.time() - start, 4)}s')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35326b77c6c42785"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Save the posterior -----\n",
    "with open(\"data/posterior_SNPE.pickle\", \"wb\") as f:\n",
    "    pickle.dump(posterior, f)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "698fd83b26f1193a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the posterior"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1cac18da3e8f51a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# ----- Load the posterior -----\n",
    "with open(\"data/posterior_SNPE.pickle\", \"rb\") as f:\n",
    "    posterior = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-04T13:13:50.993679Z",
     "start_time": "2024-08-04T13:13:50.974232Z"
    }
   },
   "id": "34ac8f3634e06ac7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Evaluate the posterior -----\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20930971dda1a3ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
