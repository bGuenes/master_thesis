{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from Chempy.parameter import ModelParameters\n",
    "\n",
    "import sbi.utils as utils\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.analysis import pairplot\n",
    "\n",
    "import torch\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "import time as t\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5651d25c573ec16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da844fae726a32e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------ Load & prepare the data ------\n",
    "\n",
    "# --- Load in training data ---\n",
    "path_training = '../ChempyMulti/tutorial_data/TNG_Training_Data.npz'\n",
    "training_data = np.load(path_training, mmap_mode='r')\n",
    "\n",
    "elements = training_data['elements']\n",
    "train_x = training_data['params']\n",
    "train_y = training_data['abundances']\n",
    "\n",
    "\n",
    "# ---  Load in the validation data ---\n",
    "path_test = '../ChempyMulti/tutorial_data/TNG_Test_Data.npz'\n",
    "val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "val_x = val_data['params']\n",
    "val_y = val_data['abundances']\n",
    "\n",
    "\n",
    "# --- Clean the data ---\n",
    "# Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "def clean_data(x, y):\n",
    "    # Remove all zeros from the training data\n",
    "    index = np.where((y == 0).all(axis=1))[0]\n",
    "    x = np.delete(x, index, axis=0)\n",
    "    y = np.delete(y, index, axis=0)\n",
    "\n",
    "    # Remove all infinite values from the training data\n",
    "    index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_x, train_y = clean_data(train_x, train_y)\n",
    "val_x, val_y     = clean_data(val_x, val_y)\n",
    "\n",
    "# convert to torch tensors\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "197d45fe9c2c3049"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = ModelParameters()\n",
    "labels = [a.to_optimize[i] for i in range(len(a.to_optimize))] + ['time']\n",
    "priors = torch.tensor([[a.priors[opt][0], a.priors[opt][1]] for opt in a.to_optimize])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbb2b36f70fe6637"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the NN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec047e04bed15c02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print(\"mps available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    print(\"using cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class Model_Torch(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_Torch, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(train_x.shape[1], 100)\n",
    "        self.l2 = torch.nn.Linear(100, 40)\n",
    "        self.l3 = torch.nn.Linear(40, train_y.shape[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.l1(x))\n",
    "        x = torch.tanh(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "model = Model_Torch()\n",
    "model.to(device);"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "771bd6cef2b791b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac1bf0bfd03c2313"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# shuffle the data\n",
    "index = np.arange(train_x.shape[0])\n",
    "np.random.shuffle(index)\n",
    "train_x = train_x[index]\n",
    "train_y = train_y[index]\n",
    "\n",
    "# --- Train the neural network ---\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "ep_loss = []\n",
    "start = t.time()\n",
    "for epoch in range(epochs):\n",
    "    start_epoch = t.time()\n",
    "    train_loss = []\n",
    "    for i in range(0, train_x.shape[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get the batch\n",
    "        x_batch = train_x[i:i+batch_size].to(device).requires_grad_(True)\n",
    "        y_batch = train_y[i:i+batch_size].to(device).requires_grad_(True)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Validation loss\n",
    "    y_pred = model(val_x)\n",
    "    val_loss = loss_fn(y_pred, val_y)\n",
    "    \n",
    "    train_loss = np.array(train_loss).mean()\n",
    "    ep_loss.append([train_loss, val_loss.item()])\n",
    "        \n",
    "    end_epoch = t.time()\n",
    "    epoch_time = end_epoch - start_epoch\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs} in {round(epoch_time,1)}s, Loss: {round(train_loss,6)} | Val Loss: {round(val_loss.item(),6)}')\n",
    "print(f'Training finished | Total time: {round(end_epoch - start, 1)}s')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc674932e28392b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ep_loss = np.array(ep_loss)\n",
    "\n",
    "plt.plot(np.arange(epochs)+1, ep_loss[:,0], label='Training Loss')\n",
    "plt.plot(np.arange(epochs)+1, ep_loss[:,1], label='Validation Loss')\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('MSE Loss', fontsize=14)\n",
    "plt.title('Training and Validation Loss', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dee7b2b4de2f49b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Calculate the L1 error ---\n",
    "l1_err = np.abs(model(val_x).detach().numpy() - val_y.numpy())\n",
    "p1,p2,p3=np.percentile(l1_err,[15.865,50.,100-17.865],axis=0).mean(axis=1)\n",
    "\n",
    "plt.hist(l1_err.flatten(), range=[0,.08], bins=100, density=True)\n",
    "plt.xlabel(r'L1 Error [dex]', fontsize=14)\n",
    "plt.ylabel(r'PDF', fontsize=14)\n",
    "\n",
    "plt.title(r'L1 error (averaged across elements): %.3f-%.3f+%.3f'%(p2,p2-p1,p3-p2), fontsize=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4df62916d3c10c4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Save the model ---\n",
    "torch.save(model.state_dict(), 'data/pytorch_state_dict.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "715398975ac1e67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train SBI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90e9435d8354a086"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Load the model -----\n",
    "model = Model_Torch()\n",
    "model.load_state_dict(torch.load('data/pytorch_state_dict.pt'))\n",
    "model.to(device)\n",
    "model.eval();"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6acdfd8f78add5f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Define the prior -----\n",
    "combined_priors = utils.MultipleIndependent(\n",
    "    [Normal(p[0]*torch.ones(1), p[1]*torch.ones(1)) for p in priors] +\n",
    "    [Uniform(torch.tensor([2.0]), torch.tensor([12.8]))],\n",
    "    validate_args=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21d67937e4b8172"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----- Setup simulator -----\n",
    "def simulator(params):\n",
    "    params = params.to(device)\n",
    "    y = model(params)\n",
    "    return y.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10f620d55d7f519f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulator, prior = prepare_for_sbi(simulator, combined_priors)\n",
    "inference = SNPE(prior=prior)\n",
    "\n",
    "start = t.time()\n",
    "\n",
    "theta, x = simulate_for_sbi(simulator, proposal=prior, num_simulations=10000)\n",
    "density_estimator = inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior(density_estimator)\n",
    "\n",
    "end = t.time()\n",
    "comp_time = end - start\n",
    "print(f'Time taken to train the posterior with {len(train_y)} samples: '\n",
    "      f'{np.floor(comp_time/60).astype(\"int\")}min {np.floor(comp_time%60).astype(\"int\")}s')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24a9576707985533"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Save the posterior ---    \n",
    "with open('data/posterior_SNPE_torch.pickle', 'wb') as f:\n",
    "    pickle.dump(posterior, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "118b6146371f2080"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize the posterior"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0e6b4d515d6912e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('data/posterior_SNPE_torch.pickle', 'rb') as f:\n",
    "    posterior = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d716f5e33c3314"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pick a random point from the validation data\n",
    "index = np.random.randint(0, len(val_x))\n",
    "x = val_x[index]\n",
    "y = val_y[index]\n",
    "\n",
    "print(f'Index: {index}')\n",
    "print(f'x: {x}')\n",
    "# sample 10000 points from the posterior\n",
    "posterior_samples = posterior.sample((10000,), x=y)\n",
    "# plot the posterior samples\n",
    "_ = pairplot(posterior_samples, figsize=(15, 15), points=x, labels=labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2092df10233b2599"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(15, 10))\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    (mu, sigma) = norm.fit(posterior_samples.numpy().T[i])\n",
    "    true_value = val_x[index][i].numpy()\n",
    "\n",
    "    deviation = abs(true_value - mu) / sigma\n",
    "    \n",
    "    ax[i//3, i%3].hist(posterior_samples.numpy().T[i], bins=50, density=True, alpha=0.6, color='g')\n",
    "    xmin, xmax = ax[i//3, i%3].get_xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, sigma)\n",
    "    ax[i//3, i%3].plot(x, p, 'k', linewidth=2)\n",
    "    ax[i//3, i%3].axvline(x=true_value, color='r', linestyle='dashed', linewidth=2)\n",
    "    \n",
    "    ax[i//3, i%3].set_title(fr\"{labels[i]}: {true_value:.2f}\"\n",
    "                            \"\\n\"\n",
    "                            fr\"$\\mu$: {mu:.2f} $\\sigma$: {sigma:.2f}\"\n",
    "                            \"\\n\"\n",
    "                            fr\"Deviation: {deviation:.2f} $\\sigma$\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaed0fb0059e8e9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Priors:\")\n",
    "for i in range(len(priors)):\n",
    "    print(fr'{labels[i]}: {priors[i][0].item():.2f} +/- {priors[i][1].item():.2f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f57d7981a5e6f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
